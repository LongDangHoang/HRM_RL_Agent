{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c404723b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/HRM_Agent/.venv/lib/python3.11/site-packages/minihack/base.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "\n",
    "import torch\n",
    "\n",
    "from rl.agent import (\n",
    "    HRMQNetTrainingConfig,\n",
    ")\n",
    "from rl.dataset import (\n",
    "    MiniHackFullObservationSimpleEnvironmentDataset,\n",
    ")\n",
    "from rl.dqn_train_loop import HRMAgentTrainingModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443e17ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get config\n",
    "from hydra import compose, initialize_config_dir\n",
    "from omegaconf import OmegaConf, SCMode\n",
    "\n",
    "with initialize_config_dir(\n",
    "    version_base=None,\n",
    "    config_dir=str(Path(\"../rl/config\").resolve()),\n",
    "    job_name=\"test_cfg\",\n",
    "):\n",
    "    cfg = compose(config_name=\"cfg_dqn.yaml\")\n",
    "\n",
    "typed_cfg: HRMQNetTrainingConfig = OmegaConf.to_container(\n",
    "    OmegaConf.merge(OmegaConf.structured(HRMQNetTrainingConfig), cfg),\n",
    "    structured_config_mode=SCMode.INSTANTIATE,\n",
    ")\n",
    "\n",
    "# for speed, we will reduce batch size, number of frames, etc.\n",
    "typed_cfg.dataset.env_kwargs[\"observation_keys\"] = [\"chars\"]\n",
    "typed_cfg.dataset.env_name = \"MiniHack-4-Rooms\"\n",
    "typed_cfg.resume_from_run = None\n",
    "typed_cfg.dataset.seq_len = 121\n",
    "typed_cfg.dataset.data_collection_batch_size = 32\n",
    "typed_cfg.dataset.frames_per_update = 320\n",
    "typed_cfg.log_wandb = False\n",
    "typed_cfg.dataset.buffer_capacity = 6000  # make sure the buffer is not exhausted otherwise it will be hard to check continuity of prev_seed_h_init and seed_h_init\n",
    "\n",
    "typed_cfg.max_training_steps = 50\n",
    "\n",
    "# set 4 or 8 way\n",
    "typed_cfg.dataset.action_space_size = 4\n",
    "typed_cfg.dataset.vocab_size = 131  # if 8, else 131\n",
    "typed_cfg.dataset.env_kwargs[\"action-space\"] = 4\n",
    "\n",
    "# undo set hidden state as reseeding\n",
    "typed_cfg.use_last_hidden_state_to_seed_next_environment_step = True\n",
    "typed_cfg.dataset.do_not_skip_running_model_if_random_action = (\n",
    "    typed_cfg.use_last_hidden_state_to_seed_next_environment_step\n",
    ")\n",
    "\n",
    "# if reseeding, data collection batch size must match\n",
    "typed_cfg.dataset.training_batch_size = typed_cfg.dataset.data_collection_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e125c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run has no name, checkpointing will not be performed\n",
      " 98%|█████████▊| 49/50 [00:22<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between trained H_init and original: tensor(0., device='cuda:0', dtype=torch.bfloat16)\n",
      "MSE between trained L_init and original: tensor(0., device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load config and initialise QValue net as well as iterable dataset\n",
    "# requires a base data\n",
    "dataset = MiniHackFullObservationSimpleEnvironmentDataset(config=typed_cfg.dataset)\n",
    "\n",
    "with torch.device(\n",
    "    \"cuda\"\n",
    "):  # make sure that the buffers used in HRM are initialised on CUDA for backprop\n",
    "    hrm_agent_training_module = HRMAgentTrainingModule(typed_cfg, dataset)\n",
    "\n",
    "original_h_init = (hrm_agent_training_module.qvalue_net.model.inner.H_init).clone()\n",
    "original_l_init = (hrm_agent_training_module.qvalue_net.model.inner.L_init).clone()\n",
    "\n",
    "dataset.initialise_policy_and_collector(\n",
    "    hrm_agent_training_module.actor,\n",
    "    hrm_agent_training_module.egreedy_module,  # pyright: ignore[reportArgumentType]\n",
    ")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "hrm_agent_training_module.pre_training_setup(\n",
    "    checkpoint_dir=None,  # this is for local, for s3 run, change to \"s3\"\n",
    "    run_name=None,  # this is for local, for s3 run with wandb, leave as None\n",
    ")\n",
    "for current_step, training_batch in tqdm(\n",
    "    enumerate(dataset, start=hrm_agent_training_module.state.global_step),\n",
    "    total=typed_cfg.max_training_steps,\n",
    "):\n",
    "    training_batch = training_batch.to(torch.device(\"cuda\"))\n",
    "    hrm_agent_training_module.training_step(training_batch)\n",
    "    hrm_agent_training_module.post_training_step_callbacks()\n",
    "\n",
    "    if current_step + 1 == typed_cfg.max_training_steps:\n",
    "        break\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\n",
    "        \"MSE between trained H_init and original:\",\n",
    "        (\n",
    "            (original_h_init - hrm_agent_training_module.qvalue_net.model.inner.H_init)\n",
    "            ** 2\n",
    "        ).sum()\n",
    "        / typed_cfg.arch_exclude_data_dependent.hidden_size,\n",
    "    )\n",
    "    print(\n",
    "        \"MSE between trained L_init and original:\",\n",
    "        (\n",
    "            (original_l_init - hrm_agent_training_module.qvalue_net.model.inner.L_init)\n",
    "            ** 2\n",
    "        ).sum()\n",
    "        / typed_cfg.arch_exclude_data_dependent.hidden_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f0a081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (3, 5)]\n",
      "[(0, 3)]\n"
     ]
    }
   ],
   "source": [
    "# some utils\n",
    "def true_ranges(lst):\n",
    "    ranges = []\n",
    "    start = None\n",
    "    for i, val in enumerate(lst):\n",
    "        if val:\n",
    "            if start is not None:\n",
    "                ranges.append((start, i - 1))\n",
    "            start = i\n",
    "    if start is not None and start < len(lst):\n",
    "        ranges.append((start, len(lst) - 1))\n",
    "    return ranges\n",
    "\n",
    "\n",
    "# Example:\n",
    "lst = [True, False, False, True, False, False]\n",
    "print(true_ranges(lst))  # [(0, 2), (3, 5)]\n",
    "lst = [True, False, False, False]\n",
    "print(true_ranges(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451cb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode_idx in range(32):\n",
    "    episode_buffer_idx = torch.arange(episode_idx, len(dataset.buffer), 32)\n",
    "    init_flags = dataset.buffer[episode_buffer_idx][\"is_init\"]\n",
    "    individual_ranges = true_ranges(init_flags[:, 0])\n",
    "\n",
    "    for range_start, range_end in individual_ranges:\n",
    "        range_buffer_idx = episode_buffer_idx[range_start : range_end + 1]\n",
    "        prev_seed_h_init = dataset.buffer[range_buffer_idx][\"prev_seed_h_init\"]\n",
    "        prev_seed_l_init = dataset.buffer[range_buffer_idx][\"prev_seed_l_init\"]\n",
    "        seed_h_init = dataset.buffer[range_buffer_idx][\"seed_h_init\"]\n",
    "        seed_l_init = dataset.buffer[range_buffer_idx][\"seed_l_init\"]\n",
    "\n",
    "        # check that previous = seed of next, and that the first previous is H_init/L_init\n",
    "        assert (\n",
    "            prev_seed_h_init[0, :].cpu()\n",
    "            == hrm_agent_training_module.qvalue_net.model.inner.H_init.cpu()\n",
    "        ).all()\n",
    "        assert (\n",
    "            prev_seed_l_init[0, :].cpu()\n",
    "            == hrm_agent_training_module.qvalue_net.model.inner.L_init.cpu()\n",
    "        ).all()\n",
    "        assert (prev_seed_h_init[1:, :].cpu() == seed_h_init[:-1, :].cpu()).all()\n",
    "        assert (prev_seed_l_init[1:, :].cpu() == seed_l_init[:-1, :].cpu()).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
