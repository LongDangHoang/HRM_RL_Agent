{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5947a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import count\n",
    "from typing import Callable\n",
    "from pathlib import Path\n",
    "from matplotlib.lines import Line2D\n",
    "import pickle\n",
    "from tensordict import TensorDict\n",
    "from utils.a_star import a_star\n",
    "\n",
    "def get_convergence_divergence_metrics(\n",
    "    trajectories: TensorDict, \n",
    "    dg_shape: tuple[int, int], \n",
    "    latent_key: str = \"running_z_H\",\n",
    "    against_env_init_latents=False, \n",
    "    against_seed_latents=False,\n",
    "    against_first_latents=False,\n",
    "):\n",
    "    ignore_repeat_after_termination_mask = torch.logical_and(trajectories[\"next\"][\"reward\"][:, :, 0] == 1, torch.roll(trajectories[\"next\"][\"reward\"][:, :, 0], shifts=1, dims=1) == 1)\n",
    "    ignore_repeat_after_termination_mask[:, 0] = True # Mask the first as it action is kinda special since the model always start from init, We want to chart convergence speed given different inits and environment change flag\n",
    "\n",
    "    latent_values = trajectories[latent_key] # (bs, num_env_steps, recursive_steps, hd)\n",
    "\n",
    "    if against_env_init_latents:\n",
    "        assert not against_seed_latents and not against_first_latents\n",
    "        comparison_latents = trajectories[latent_key][:, 0, 0, :].unsqueeze(1).unsqueeze(1) # (bs, 1, 1, hd)\n",
    "    elif against_seed_latents:\n",
    "        assert not against_first_latents\n",
    "        comparison_latents = trajectories[latent_key][:, :, 0, :].unsqueeze(2) # (bs, num_env_steps, 1, hd)\n",
    "    elif against_first_latents:\n",
    "        comparison_latents = trajectories[latent_key][:, :, 1, :].unsqueeze(2) # (bs, num_env_steps, 1, hd)\n",
    "    else:\n",
    "        comparison_latents = trajectories[latent_key][:, :, -1, :].unsqueeze(2) # (bs, num_env_steps, 1, hd)\n",
    "\n",
    "    diff_mse = (((comparison_latents - latent_values) ** 2).sum(dim=-1) / latent_values.shape[-1]) # (bs, num_env_steps, recursive_steps)\n",
    "    \n",
    "    last_reward = torch.roll(trajectories[\"next\"][\"reward\"][:, :, 0], shifts=1, dims=-1) # (bs, num_env_steps)\n",
    "    mask = (last_reward == 1) # (bs, num_env_steps)\n",
    "    mask[:, 0] = True # ignore first action\n",
    "\n",
    "    # get change flag for each env_step\n",
    "    change_from_prev_flags = [torch.as_tensor([True] * latent_values.shape[0], dtype=torch.bool)]  # first step always add the first door\n",
    "    for env_step in range(1, latent_values.shape[1]):\n",
    "        # get change flag for this env step\n",
    "        inputs = trajectories[\"inputs\"][:, env_step, :] # (bs, seq_len)\n",
    "        last_inputs = trajectories[\"inputs\"][:, env_step - 1, :] # (bs, seq_len)\n",
    "        inputs_ignored_actor_start = torch.where(torch.logical_or(inputs == ord(\"@\"), inputs == ord(\"<\")), ord(\".\"), inputs)  # mask out the actor and start goal so the only change is in the doors of the env\n",
    "        last_inputs_ignored_actor_start = torch.where(torch.logical_or(last_inputs == ord(\"@\"), last_inputs == ord(\"<\")), ord(\".\"), last_inputs)  # mask out the actor and start goal so the only change is in the doors of the env\n",
    "        env_change_at_all = (last_inputs_ignored_actor_start != inputs_ignored_actor_start).any(dim=-1)  #(bs)\n",
    "\n",
    "        change_from_prev_flags.append([])\n",
    "        for env_idx in range(latent_values.shape[0]):\n",
    "            # if env didn't change at all, skip\n",
    "            if not env_change_at_all[env_idx]:\n",
    "                change_from_prev_flags[-1].append(False)\n",
    "                continue\n",
    "\n",
    "            # reconstruct the env_idx\n",
    "            prev_input_at_env_idx = last_inputs[env_idx, :].reshape(dg_shape).T\n",
    "            prev_agent_pos = list(map(int, torch.nonzero(prev_input_at_env_idx == ord(\"@\"), as_tuple=True)))[::-1]\n",
    "            prev_goal_pos = list(map(int, torch.nonzero(prev_input_at_env_idx == ord(\">\"), as_tuple=True)))[::-1]\n",
    "            changed_locations = torch.nonzero(last_inputs_ignored_actor_start[env_idx, :].reshape(dg_shape).T != inputs_ignored_actor_start[env_idx, :].reshape(dg_shape).T, as_tuple=True)\n",
    "\n",
    "            # do a-star\n",
    "            prev_input_at_env_idx_str = [[chr(val) if chr(val) not in (\"|\", \"-\", \"#\") else \"|\" for val in row] for row in prev_input_at_env_idx.T]\n",
    "            path_from_agent_to_goal = a_star(prev_input_at_env_idx_str, start=prev_agent_pos, goal=prev_goal_pos, obstacle=\"|\")\n",
    "\n",
    "            # check that the door being updated is not on the path\n",
    "            if path_from_agent_to_goal is not None:\n",
    "                change_flag = False\n",
    "                for c, r in zip(*changed_locations):\n",
    "                    if [int(r), int(c)] in path_from_agent_to_goal[1:]: # skip the first one since it includes the agent_pos\n",
    "                        change_flag = True\n",
    "                        break\n",
    "\n",
    "            else: # path only change if there is path now\n",
    "                current_input_at_env_idx = inputs[env_idx, :].reshape(dg_shape)\n",
    "                current_agent_pos = list(map(int, torch.nonzero(current_input_at_env_idx == ord(\"@\"), as_tuple=True)))[::-1]\n",
    "                current_input_at_env_idx_str = [[ chr(val) if chr(val) not in (\"|\", \"-\", \"#\") else \"|\" for val in row] for row in current_input_at_env_idx.T]\n",
    "                change_flag = a_star(current_input_at_env_idx_str, start=current_agent_pos, goal=prev_goal_pos, obstacle=\"|\") is not None\n",
    "            \n",
    "            change_from_prev_flags[-1].append(change_flag)\n",
    "    \n",
    "        change_from_prev_flags[-1] = torch.as_tensor(change_from_prev_flags[-1], dtype=torch.bool) # (bs)\n",
    "    change_from_prev_flags = torch.stack(change_from_prev_flags, dim=1) # (bs, num_env_steps)\n",
    "\n",
    "    # change_from_prev_flags = change_from_p?rev_flags != 2 # all true\n",
    "\n",
    "    # we want to know for each recursive step and change flag, what the avg mse is and what the size of the support\n",
    "    mask_change_flag_true = (~mask) * change_from_prev_flags # (bs, num_env_steps)\n",
    "    mask_change_flag_false = (~mask) * (~change_from_prev_flags) # (bs, num_env_steps)\n",
    "\n",
    "\n",
    "    masked_change_true_diff_mse = torch.masked_select(diff_mse, mask_change_flag_true.unsqueeze(2)) # (bs, num_env_steps, recursive_steps)\n",
    "    support_mask_change_flag_true = mask_change_flag_true.sum() # scalar\n",
    "    mse_avg_recursive_step__change_flag_true = masked_change_true_diff_mse.sum() / support_mask_change_flag_true # scalar\n",
    "\n",
    "    masked_change_false_diff_mse = torch.masked_select(diff_mse, mask_change_flag_false.unsqueeze(2)) # (bs, num_env_steps, recursive_steps)\n",
    "    support_mask_change_flag_false = mask_change_flag_false.sum() # scalar\n",
    "    mse_avg_recursive_step__change_flag_false = masked_change_false_diff_mse.sum() / support_mask_change_flag_false # (recursive step)\n",
    "\n",
    "    return {\n",
    "        \"mse_avg_change_env\": mse_avg_recursive_step__change_flag_true, # recursive step values\n",
    "        \"change_env_support\": support_mask_change_flag_true,\n",
    "        \"mse_avg_no_change_env\": mse_avg_recursive_step__change_flag_false, # recursive step values\n",
    "        \"no_change_env_support\": support_mask_change_flag_false,\n",
    "        \"change_flags\": change_from_prev_flags,\n",
    "        \"diff_mse\": diff_mse,\n",
    "        \"mask_change_flag_true\": mask_change_flag_true,\n",
    "        \"mask_change_flag_false\": mask_change_flag_false,\n",
    "        \"num_envs_solved\": int((trajectories[\"next\"][\"reward\"][:, -1, 0] == 1).sum()),\n",
    "        \"num_envs_totaled\": trajectories.shape[0],\n",
    "    }\n",
    "\n",
    "\n",
    "def find_all_runs_matching_desc(\n",
    "    plots_dir: Path,\n",
    "    reseeding_flag: bool = True,\n",
    "    env_name: str = \"MiniHack-4-Rooms\",\n",
    "    intervention: str = \"None\",\n",
    "):\n",
    "    for pkl_file in plots_dir.glob(\"*.pkl\"):\n",
    "        if pkl_file.name.endswith(f\"_reseeding={reseeding_flag}_env={env_name}_intervetion={intervention}.pkl\"):  # oopse misspelt\n",
    "            yield pkl_file\n",
    "\n",
    "def plot_convergence_divergence(\n",
    "    env_name: str,\n",
    "    intervention: str,\n",
    "    dg_shape: tuple[int, int],\n",
    "    pickles_dir: Path,\n",
    "    plots_dir: Path | None = None,\n",
    "    against_env_init_latents: bool = False,\n",
    "    against_seed_latents: bool = False,\n",
    "    against_first_latents: bool = False,\n",
    "    title: str | None = None,\n",
    "    y_label: str = \"Median MSE\",\n",
    "    plot_func: Callable[torch.Tensor, torch.Tensor] = lambda y_tensor: torch.quantile(y_tensor, q=torch.tensor([0.5]), dim=0).squeeze(),\n",
    "    y_scale: str=\"linear\",\n",
    "):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(20, 8), constrained_layout=True)\n",
    "\n",
    "    if plots_dir is None:\n",
    "        plots_dir = pickles_dir.parent / \"plots_pngs\"\n",
    "        plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for plot_idx, key in enumerate((\"running_z_L\", \"running_z_H\")):\n",
    "        ax = axs[plot_idx]\n",
    "        ax.set_title(key.replace(\"running_\", \"\"), fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "        line_counter = count(0)\n",
    "        data_records = []\n",
    "        metadata_records = {}\n",
    "\n",
    "        dash_styles = {}\n",
    "\n",
    "        # Aggregate all data into a long-format list for seaborn\n",
    "        for reseeding_flag in (True, False):\n",
    "            measurement_metrics = []\n",
    "\n",
    "            for pkl_file in find_all_runs_matching_desc(\n",
    "                plots_dir=pickles_dir, reseeding_flag=reseeding_flag,\n",
    "                env_name=env_name, intervention=intervention\n",
    "            ):\n",
    "                print(f\"Reading pickle {pkl_file}\")\n",
    "                with open(pkl_file, \"rb\") as f:\n",
    "                    trajectories = pickle.load(f)\n",
    "\n",
    "                measurement_metrics.append(get_convergence_divergence_metrics(\n",
    "                    trajectories=trajectories,\n",
    "                    dg_shape=dg_shape,\n",
    "                    latent_key=key,\n",
    "                    against_env_init_latents=against_env_init_latents,\n",
    "                    against_seed_latents=against_seed_latents,\n",
    "                    against_first_latents=against_first_latents,\n",
    "                ))\n",
    "\n",
    "            for change_flag in (True, False):\n",
    "                mask_key = f\"mask_change_flag_{change_flag}\".lower()\n",
    "\n",
    "                X_ALL = list(range(measurement_metrics[0][\"diff_mse\"].shape[-1]))\n",
    "                Y_ALL = [[] for _ in range(len(X_ALL))]\n",
    "\n",
    "                for m in measurement_metrics:\n",
    "                    Y_tensor = m[\"diff_mse\"]\n",
    "                    MASK = m[mask_key]\n",
    "                    for step in range(Y_tensor.shape[-1]):\n",
    "                        Y_ALL[step].extend(torch.masked_select(Y_tensor[:, :, step], MASK).float())\n",
    "\n",
    "                Y_ALL = torch.tensor(Y_ALL) # (recursion_steps, N_ALL)\n",
    "                plot_y = plot_func(torch.swapaxes(Y_ALL, 0, 1))\n",
    "\n",
    "                if y_scale == \"log\":\n",
    "                    plot_y = torch.maximum(plot_y, torch.tensor(torch.finfo(torch.float32).eps))\n",
    "\n",
    "                label = (\n",
    "                    \"Carry Z\" if reseeding_flag else \"Reset Z\"\n",
    "                ) + \" - \" + (\n",
    "                    \"Env. changed\" if change_flag else \"Env. static\"\n",
    "                ) + f\" (N={Y_ALL.shape[1]})\"\n",
    "\n",
    "                dash_styles[label] = '' if reseeding_flag else (2, 2)\n",
    "\n",
    "                for x, y in zip(X_ALL[1:-1], plot_y[1:-1].numpy()):\n",
    "                    data_records.append({\n",
    "                        \"Recurrent step\": x,\n",
    "                        \"Median MSE\": y,\n",
    "                        \"Condition\": label\n",
    "                    })\n",
    "\n",
    "            metadata_records[reseeding_flag] = {\n",
    "                \"num_envs\": sum(m[\"num_envs_totaled\"] for m in measurement_metrics),\n",
    "                \"num_envs_solved\": sum(m[\"num_envs_solved\"] for m in measurement_metrics),\n",
    "            }\n",
    "            metadata_records[reseeding_flag][\"frac_solved\"] = (\n",
    "                metadata_records[reseeding_flag][\"num_envs_solved\"] \n",
    "                / metadata_records[reseeding_flag][\"num_envs\"]\n",
    "            )\n",
    "\n",
    "        # --- Plot with seaborn ---\n",
    "        sns.lineplot(\n",
    "            data=pd.DataFrame(data_records),\n",
    "            x=\"Recurrent step\",\n",
    "            y=\"Median MSE\",\n",
    "            hue=\"Condition\",\n",
    "            ax=ax,\n",
    "            style=\"Condition\",\n",
    "            dashes=dash_styles,\n",
    "            palette=\"colorblind\",\n",
    "            linewidth=2,\n",
    "            legend=plot_idx == len(axs) - 1,\n",
    "        )\n",
    "\n",
    "        if plot_idx == 0:\n",
    "            ax.set_ylabel(\"Median MSE\" if y_label is None else y_label, fontsize=14)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\", fontsize=14)\n",
    "\n",
    "        ax.set_xlabel(\"Recurrent step\", fontsize=16)\n",
    "\n",
    "        ax.set_yscale(y_scale)\n",
    "\n",
    "        if plot_idx == len(axs) - 1:\n",
    "            meta_legend = [\n",
    "                Line2D([], [], color='none', label=f'Carry Z: {metadata_records[True][\"frac_solved\"]*100:.1f}%'),\n",
    "                Line2D([], [], color='none', label=f'Reset Z: {metadata_records[False][\"frac_solved\"]*100:.1f}%')\n",
    "            ]\n",
    "            \n",
    "            # Add the secondary metadata legend aligned left with the first\n",
    "            info_legend = ax.legend(\n",
    "                handles=meta_legend,\n",
    "                loc='upper left',\n",
    "                bbox_to_anchor=(1.02, 0.75),  # same x (1.02), slightly lower y\n",
    "                frameon=False,\n",
    "                title=f'Environments solved (N={sum(int(d[\"num_envs\"]) for d in metadata_records.values()) // 2}):', # reseeding and non-reseeding\n",
    "                title_fontsize=16,\n",
    "                fontsize=16,\n",
    "            )\n",
    "\n",
    "            # add the main legend as it is longer and we want it used to define the width of the figure\n",
    "            ax.legend(title=None, frameon=False, loc=\"upper left\", bbox_to_anchor=(1.02, 1), fontsize=16)\n",
    "\n",
    "            # Ensure the first legend remains visible (since adding a new one replaces the previous)\n",
    "            ax.add_artist(info_legend)\n",
    "\n",
    "    if title is None:\n",
    "        title = f\"Convergence of hidden states for {X_ALL[-1]} recurrent steps - {env_name}\"\n",
    "    fig.suptitle(title, fontsize=18) #, fontweight=\"bold\")    \n",
    "    plt.savefig(plots_dir / (title.lower().replace(\" \", \"_\").replace(\"-\", \"_\") + \".png\"), dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de25787",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/incubator/dev/hrm/s3/pickles\"\n",
    "metadata_dict = {\n",
    "    \"psy7bpwq\": {\n",
    "        \"model_trained_on_reseeding\": True,\n",
    "        \"env\": \"4-Room\",\n",
    "    },\n",
    "    \"u2fivtrs\": {\n",
    "        \"model_trained_on_reseeding\": False,\n",
    "        \"env\": \"4-Room\",\n",
    "    },\n",
    "    \"nq3r9hsw\": {\n",
    "        \"model_trained_on_reseeding\": False,\n",
    "        \"env\": \"Dynamic-Maze\",\n",
    "    },\n",
    "    \"f79zuqjx\": {\n",
    "        \"model_trained_on_reseeding\": True,\n",
    "        \"env\": \"Dynamic-Maze\",\n",
    "    }\n",
    "}\n",
    "\n",
    "UNIQUE_DESCS = (\"4-rooms, carry Z\", \"4-rooms, reset Z\", \"Maze, carry Z\", \"Maze, reset Z\")\n",
    "\n",
    "PLOTS_OUTPUT_DIR = Path(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30164a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_shape = (11, 11)\n",
    "env_name = \"MiniHack-4-Rooms\"\n",
    "\n",
    "plot_convergence_divergence(\n",
    "    dg_shape=dg_shape,\n",
    "    env_name=env_name,\n",
    "    intervention=\"None\",\n",
    "    pickles_dir=PLOTS_OUTPUT_DIR,\n",
    "    title=\"Convergence of recurrent state $z$ to final values - 4-rooms environment\",\n",
    "    y_scale=\"log\",\n",
    "    #y_scale=\"linear\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a105af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_shape = (11, 13)\n",
    "env_name = \"MiniHack-Corridor-Maze-4-Way-Dynamic\"\n",
    "\n",
    "plot_convergence_divergence(\n",
    "    dg_shape=dg_shape,\n",
    "    env_name=env_name,\n",
    "    intervention=\"None\",\n",
    "    pickles_dir=PLOTS_OUTPUT_DIR,\n",
    "    title=\"Convergence of recurrent state $z$ to final values: Maze environment\",\n",
    "    y_scale=\"log\",\n",
    "    #y_scale=\"linear\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e468eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_shape = (11, 13)\n",
    "env_name = \"MiniHack-Corridor-Maze-4-Way-Dynamic\"\n",
    "\n",
    "plot_convergence_divergence(\n",
    "    dg_shape=dg_shape,\n",
    "    env_name=env_name,\n",
    "    intervention=\"None\",\n",
    "    pickles_dir=PLOTS_OUTPUT_DIR,\n",
    "    title=\"Divergence of recurrent state $z$ from initial values: Maze environment\",\n",
    "    against_first_latents=True,\n",
    "    y_scale=\"log\",\n",
    "    #y_scale=\"linear\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".hrm-env (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
